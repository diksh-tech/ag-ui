import os
import uuid
from typing import AsyncGenerator
from fastapi import FastAPI, Request
from fastapi.responses import StreamingResponse
from ag_ui.core import (
    RunAgentInput,
    EventType,
    RunStartedEvent,
    RunFinishedEvent,
    TextMessageStartEvent,
    TextMessageContentEvent,
    TextMessageEndEvent,
    ToolCallStartEvent,
    ToolCallArgsEvent,
    ToolCallEndEvent,
)
from ag_ui.encoder import EventEncoder
from openai import AzureOpenAI
from dotenv import load_dotenv

load_dotenv()

app = FastAPI(title="FlightOps AG-UI Server")

# Azure OpenAI client
client = AzureOpenAI(
    api_key=os.getenv("AZURE_OPENAI_KEY"),
    api_version=os.getenv("AZURE_API_VERSION", "2024-12-01-preview"),
    azure_endpoint=os.getenv("AZURE_OPENAI_ENDPOINT")
)

@app.post("/agent")
async def flight_agent_endpoint(input_data: RunAgentInput, request: Request):
    """AG-UI compatible flight operations agent"""
    accept_header = request.headers.get("accept", "text/event-stream")
    encoder = EventEncoder(accept=accept_header)

    async def event_generator() -> AsyncGenerator[str, None]:
        try:
            # Emit RUN_STARTED
            yield encoder.encode(
                RunStartedEvent(
                    type=EventType.RUN_STARTED,
                    thread_id=input_data.thread_id,
                    run_id=input_data.run_id
                )
            )

            # Convert messages to OpenAI format
            messages = [
                {
                    "role": msg.role,
                    "content": msg.content or "",
                }
                for msg in input_data.messages
            ]

            # Call Azure OpenAI with streaming
            stream = client.chat.completions.create(
                model=os.getenv("AZURE_OPENAI_DEPLOYMENT", "gpt-4o"),
                stream=True,
                messages=messages,
            )

            message_id = str(uuid.uuid4())
            
            # Emit TEXT_MESSAGE_START
            yield encoder.encode(
                TextMessageStartEvent(
                    type=EventType.TEXT_MESSAGE_START,
                    message_id=message_id,
                    role="assistant"
                )
            )

            # Stream chunks from OpenAI
            for chunk in stream:
                if chunk.choices[0].delta.content:
                    yield encoder.encode(
                        TextMessageContentEvent(
                            type=EventType.TEXT_MESSAGE_CONTENT,
                            message_id=message_id,
                            delta=chunk.choices[0].delta.content
                        )
                    )

            # Emit TEXT_MESSAGE_END
            yield encoder.encode(
                TextMessageEndEvent(
                    type=EventType.TEXT_MESSAGE_END,
                    message_id=message_id
                )
            )

            # Emit RUN_FINISHED
            yield encoder.encode(
                RunFinishedEvent(
                    type=EventType.RUN_FINISHED,
                    thread_id=input_data.thread_id,
                    run_id=input_data.run_id
                )
            )

        except Exception as error:
            from ag_ui.core import RunErrorEvent
            yield encoder.encode(
                RunErrorEvent(
                    type=EventType.RUN_ERROR,
                    message=str(error)
                )
            )

    return StreamingResponse(
        event_generator(),
        media_type="text/event-stream"
    )

if __name__ == "__main__":
    import uvicorn
    uvicorn.run("ag_ui_server:app", host="0.0.0.0", port=8001, reload=True)
####################################################################
import asyncio
import httpx
from ag_ui.core import RunAgentInput, UserMessage

async def call_ag_ui_agent():
    url = "http://localhost:8001/agent"
    
    # Prepare input
    input_data = RunAgentInput(
        thread_id="main-thread",
        run_id="run-001",
        messages=[
            UserMessage(
                id="msg-1",
                role="user",
                content="What's the status of flight 6E 215 on 2024-06-23?"
            )
        ]
    )
    
    # Make streaming request
    async with httpx.AsyncClient() as client:
        async with client.stream(
            "POST",
            url,
            json=input_data.model_dump(),
            headers={"Accept": "text/event-stream"}
        ) as response:
            async for line in response.aiter_lines():
                if line.startswith("data: "):
                    event_data = line[6:]  # Remove "data: " prefix
                    print(event_data)

if __name__ == "__main__":
    asyncio.run(call_ag_ui_agent())
