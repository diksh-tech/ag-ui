def plan_tools(self, user_query: str) -> dict:
    """
    Ask the LLM to produce a valid JSON plan for which MCP tools to call.
    Handles text responses and code blocks.
    """
    from datetime import datetime
    import re
    
    messages = [
        {"role": "system", "content": SYSTEM_PROMPT_PLAN},
        {"role": "user", "content": user_query},
    ]

    content = self._call_azure_openai(messages, temperature=0.0)  # Lower temperature
    if not content:
        logger.warning("‚ö†Ô∏è LLM returned empty response during plan generation.")
        return {"plan": []}

    # Clean the response
    cleaned = content.strip()
    
    # Remove markdown code blocks
    if "```json" in cleaned:
        # Extract JSON from code block
        match = re.search(r'```json\s*(\{.*?\})\s*```', cleaned, re.DOTALL)
        if match:
            cleaned = match.group(1)
    elif "```" in cleaned:
        # Remove any code block markers
        cleaned = re.sub(r'```[a-z]*\n?', '', cleaned)
        cleaned = cleaned.replace("```", "").strip()
    
    # Remove any text before the JSON
    if cleaned.startswith("To ") or cleaned.startswith("I will"):
        # Find the first { and extract from there
        json_start = cleaned.find('{')
        if json_start != -1:
            cleaned = cleaned[json_start:]

    logger.debug(f"üîç Cleaned LLM plan output:\n{cleaned}")

    # Try to parse JSON
    try:
        plan = json.loads(cleaned)
        if isinstance(plan, dict) and "plan" in plan:
            # Add default date if missing
            for step in plan.get("plan", []):
                args = step.get("arguments", {})
                if "date_of_origin" in args and (args["date_of_origin"] is None or args["date_of_origin"] == "null"):
                    args["date_of_origin"] = datetime.now().strftime("%Y-%m-%d")
                    logger.info(f"Added default date: {args['date_of_origin']}")
            return plan
        else:
            logger.warning("‚ö†Ô∏è LLM output did not contain 'plan' key.")
            return {"plan": []}
    except json.JSONDecodeError as e:
        logger.warning(f"‚ùå Could not parse LLM plan output: {e}\n{cleaned[:300]}")
        
        # Fallback: Try to extract flight info and create a default plan
        flight_match = re.search(r'6[Ee]\s*(\d+)', user_query)
        if flight_match:
            flight_num = flight_match.group(1)
            logger.info(f"Creating fallback plan for flight 6E{flight_num}")
            return {
                "plan": [{
                    "tool": "get_flight_basic_info",
                    "arguments": {
                        "carrier": "6E",
                        "flight_number": flight_num,
                        "date_of_origin": datetime.now().strftime("%Y-%m-%d")
                    }
                }]
            }
        
        return {"plan": []}
#####################################################################
SYSTEM_PROMPT_PLAN = f"""
You are an assistant that converts user questions into MCP tool calls.

Available tools:
{_build_tool_prompt()}

### CRITICAL RULES:
1. **ALWAYS return ONLY valid JSON** - no explanations, no text before or after
2. **NEVER use null for date_of_origin** - use today's date: {datetime.now().strftime("%Y-%m-%d")}
3. **Do NOT wrap JSON in code blocks** - return raw JSON only
4. **Format**: {{"plan": [{{"tool": "tool_name", "arguments": {{...}}}}]}}

### Tool selection logic

1. **Use `run_aggregated_query`** for counts, totals, averages, etc.
2. **Use `raw_mongodb_query`** for lists, filtered data
3. **Use existing tools** (get_flight_basic_info, get_delay_summary, etc.) for single-flight queries

### Example responses (COPY THIS FORMAT EXACTLY):

User: "give me base station of flight 6E 215"
{{
  "plan": [
    {{
      "tool": "get_flight_basic_info",
      "arguments": {{
        "carrier": "6E",
        "flight_number": "215",
        "date_of_origin": "{datetime.now().strftime("%Y-%m-%d")}"
      }}
    }}
  ]
}}

User: "delay info for 6E215"
{{
  "plan": [
    {{
      "tool": "get_delay_summary",
      "arguments": {{
        "carrier": "6E",
        "flight_number": "215",
        "date_of_origin": "{datetime.now().strftime("%Y-%m-%d")}"
      }}
    }}
  ]
}}

REMEMBER: Return ONLY the JSON object, nothing else!
"""
###################################################################
from datetime import datetime

@mcp.tool()
async def get_flight_basic_info(carrier: str = "", flight_number: str = "", date_of_origin: str = "") -> str:
    """
    Fetch basic flight information including carrier, flight number, date, stations, times, and status.
    
    Args:
        carrier: Airline carrier code (e.g., "6E", "AI")
        flight_number: Flight number as string (e.g., "215")
        date_of_origin: Date in YYYY-MM-DD format (e.g., "2024-11-04"). Defaults to today.
    """
    # Use today's date if not provided
    if not date_of_origin:
        date_of_origin = datetime.now().strftime("%Y-%m-%d")
        logger.info(f"Using default date: {date_of_origin}")
    
    logger.info(f"get_flight_basic_info: carrier={carrier}, flight_number={flight_number}, date={date_of_origin}")
    
    fn = normalize_flight_number(flight_number) if flight_number else None
    dob = validate_date(date_of_origin) if date_of_origin else None
    
    if date_of_origin and not dob:
        return response_error("Invalid date_of_origin format. Expected YYYY-MM-DD or common date formats", 400)
    
    query = make_query(carrier, fn, dob)
    # ... rest of code

























import os
import json
import logging
import asyncio
from typing import List, Dict, Any

from dotenv import load_dotenv
from openai import AzureOpenAI
from mcp import ClientSession
from mcp.client.streamable_http import streamablehttp_client

from tool_registry import TOOLS

# Load environment variables
load_dotenv()

MCP_SERVER_URL = os.getenv("MCP_SERVER_URL", "http://127.0.0.1:8000").rstrip("/")

# Azure OpenAI configuration
AZURE_OPENAI_KEY = os.getenv("AZURE_OPENAI_KEY")
AZURE_OPENAI_ENDPOINT = os.getenv("AZURE_OPENAI_ENDPOINT")
AZURE_OPENAI_DEPLOYMENT = os.getenv("AZURE_OPENAI_DEPLOYMENT", "gpt-4o")
AZURE_API_VERSION = os.getenv("AZURE_API_VERSION", "2024-12-01-preview")

if not AZURE_OPENAI_KEY:
    raise RuntimeError("‚ùå AZURE_OPENAI_KEY not set in environment")

logging.basicConfig(level=os.getenv("LOG_LEVEL", "INFO"))
logger = logging.getLogger("FlightOps.MCPClient")

# Initialize Azure OpenAI client
client_azure = AzureOpenAI(
    api_key=AZURE_OPENAI_KEY,
    api_version=AZURE_API_VERSION,
    azure_endpoint=AZURE_OPENAI_ENDPOINT
)

# ---------------------------------------------------------------------
#  SYSTEM PROMPTS
# ---------------------------------------------------------------------
def _build_tool_prompt() -> str:
    """Convert TOOLS dict into compact text to feed the LLM."""
    lines = []
    for name, meta in TOOLS.items():
        arg_str = ", ".join(meta["args"])
        lines.append(f"- {name}({arg_str}): {meta['desc']}")
    return "\n".join(lines)


SYSTEM_PROMPT_PLAN = f"""
You are an assistant that converts user questions into MCP tool calls.

Available tools:
{_build_tool_prompt()}

### Tool selection logic

1. **Use `run_aggregated_query`** when the user asks for:
   - counts, numbers, totals, sums, averages, minimums, or maximums
   - examples: "how many flights", "number of passengers", "average delay", "max flight time", "total fuel"
   - In such cases:
     - set `"query_type"` to one of ["count", "sum", "average", "min", "max"]
     - set `"field"` to the appropriate MongoDB path (e.g. "flightLegState.pax.passengerCount.count")
     - if the user gives a condition (e.g. "where delay > 30"), include it as `"filter_json"`
     - optionally include `"start_date"` and `"end_date"` for time ranges

     Example:
     {{
       "plan": [
         {{
           "tool": "run_aggregated_query",
           "arguments": {{
             "query_type": "count",
             "field": "flightLegState.pax.passengerCount.count",
             "filter_json": "{{ 'flightLegState.pax.passengerCount.count': {{ '$gt': 100 }} }}"
           }}
         }}
       ]
     }}

2. **Use `raw_mongodb_query`** for:
   - retrieving lists of flights, filtered data, or detailed fields
   - when the question asks to "show", "list", "find", or "get" specific flight data
   - supports `"projection"` to reduce payload (LLM decides what to include)

     Example:
     {{
       "plan": [
         {{
           "tool": "raw_mongodb_query",
           "arguments": {{
             "query_json": "{{ 'flightLegState.startStation': 'DEL', 'flightLegState.endStation': 'BOM' }}",
             "projection": "{{ 'flightLegState.flightNumber': 1, 'flightLegState.startStation': 1, 'flightLegState.endStation': 1, '_id': 0 }}",
             "limit": 10
           }}
         }}
       ]
     }}

3. **Use existing tools** (like get_flight_basic_info, get_delay_summary, etc.) for single-flight queries (where a flight number and date are specified).

---

### Schema summary (for projection guidance)

Flight documents contain(Schema):
    'carrier': 'flightLegState.carrier',
    'date_of_origin': 'flightLegState.dateOfOrigin',
    'flight_number': 'flightLegState.flightNumber',
    'suffix': 'flightLegState.suffix',
    'sequence_number': 'flightLegState.seqNumber',
    'origin': 'flightLegState.startStation',
    'destination': 'flightLegState.endStation',
    'scheduled_departure': 'flightLegState.scheduledStartTime',
    'scheduled_arrival': 'flightLegState.scheduledEndTime',
    'end_terminal': 'flightLegState.endTerminal',
    'operational_status': 'flightLegState.operationalStatus',
    'flight_status': 'flightLegState.flightStatus',
    'start_country': 'flightLegState.startCountry',
    'end_country': 'flightLegState.endCountry',
    'aircraft_registration': 'flightLegState.equipment.aircraftRegistration',
    'aircraft_type': 'flightLegState.equipment.assignedAircraftTypeIATA',
    'start_gate': 'flightLegState.startGate',
    'end_gate': 'flightLegState.endGate',
    'start_terminal': 'flightLegState.startTerminal',
    'delay_total': 'flightLegState.delays.total',
    'flight_type': 'flightLegState.flightType',
    'operations': 'flightLegState.operation',
    'estimated_times': 'flightLegState.operation.estimatedTimes',
    'off_block_time': 'flightLegState.operation.estimatedTimes.offBlock',
    'in_block_time': 'flightLegState.operation.estimatedTimes.inBlock',
    'takeoff_time': 'flightLegState.operation.estimatedTimes.takeoffTime',
    'landing_time': 'flightLegState.operation.estimatedTimes.landingTime',
    'actual_times': 'flightLegState.operation.actualTimes',
    'actual_off_block_time': 'flightLegState.operation.actualTimes.offBlock',
    'actual_in_block_time': 'flightLegState.operation.actualTimes.inBlock',
    'actual_takeoff_time': 'flightLegState.operation.actualTimes.takeoffTime',
    'actual_landing_time': 'flightLegState.operation.actualTimes.landingTime',
    'door_close_time': 'flightLegState.operation.estimatedTimes.doorClose',
    'fuel':'flightLegState.operation.fuel',
    'fuel_off_block':'flightLegState.operation.fuel.offBlock',
    'fuel_takeoff':'flightLegState.operation.fuel.takeoff',
    'fuel_landing':'flightLegState.operation.fuel.landing',
    'fuel_in_block':'flightLegState.operation.fuel.inBlock',
    'autoland':'flightLegState.operation.autoland',
    'flight_plan':'flightLegState.operation.flightPlan',
    'estimated_Elapsed_time':'flightLegState.operation.flightPlan.estimatedElapsedTime',
    'actual_Takeoff_time':'flightLegState.operation.flightPlan.acTakeoffWeight',
    'flight_plan_takeoff_fuel':'flightLegState.operation.flightPlan.takeoffFuel',
    'flight_plan_landing_fuel':'flightLegState.operation.flightPlan.landingFuel',
    'flight_plan_hold_fuel':'flightLegState.operation.flightPlan.holdFuel',
    'flight_plan_hold_time':'flightLegState.operation.flightPlan.holdTime',
    'flight_plan_route_distance':'flightLegState.operation.flightPlan.routeDistance',

---

### Projection rules for `raw_mongodb_query`
- Only include fields relevant to the question.
- Always exclude "_id".
- Examples:
  - ‚Äúpassenger‚Äù ‚Üí include flightNumber, pax.passengerCount
  - ‚Äúdelay‚Äù or ‚Äúreason‚Äù ‚Üí include flightNumber, delays.total, delays.delay.reason
  - ‚Äúaircraft‚Äù or ‚Äútail‚Äù ‚Üí include equipment.aircraftRegistration, aircraft.type
  - ‚Äústation‚Äù or ‚Äúsector‚Äù ‚Üí include startStation, endStation, terminals
  - ‚Äúcrew‚Äù ‚Üí include crewConnections.crew.givenName, position
  - ‚Äútiming / departure / arrival / dep / arr‚Äù ‚Üí include scheduledStartTime, scheduledEndTime, operation.actualTimes
  - ‚Äúfuel‚Äù ‚Üí include operation.fuel
  - ‚ÄúOTP‚Äù or ‚Äúon-time‚Äù ‚Üí include isOTPAchieved, flightStatus

---

### General rules
1. Always return valid JSON with a top-level "plan" key.
2. Use the correct tool type based on query intent.
3. Never invent field names ‚Äî use schema fields only.
4. Never return "_id" in projections.
5. For numerical summaries ‚Üí use run_aggregated_query.
6. For filtered listings ‚Üí use raw_mongodb_query.
"""


SYSTEM_PROMPT_SUMMARIZE = """
You are an assistant that summarizes tool outputs into a concise, readable answer.
Be factual, short, and helpful.
"""

# ---------------------------------------------------------------------
#  FLIGHTOPS MCP CLIENT CLASS
# ---------------------------------------------------------------------
class FlightOpsMCPClient:
    def __init__(self, base_url: str = None):
        self.base_url = (base_url or MCP_SERVER_URL).rstrip("/")
        self.session: ClientSession = None
        self._client_context = None

    # -------------------- CONNECTION HANDLERS -------------------------
    async def connect(self):
        try:
            logger.info(f"Connecting to MCP server at {self.base_url}")
            self._client_context = streamablehttp_client(self.base_url)
            read_stream, write_stream, _ = await self._client_context.__aenter__()
            self.session = ClientSession(read_stream, write_stream)
            await self.session.__aenter__()
            await self.session.initialize()
            logger.info("‚úÖ Connected to MCP server successfully")
        except Exception as e:
            logger.error(f"Failed to connect to MCP server: {e}")
            raise

    async def disconnect(self):
        try:
            if self.session:
                await self.session.__aexit__(None, None, None)
            if self._client_context:
                await self._client_context.__aexit__(None, None, None)
            logger.info("Disconnected from MCP server")
        except Exception as e:
            logger.error(f"Error during disconnect: {e}")

    # -------------------- AZURE OPENAI WRAPPER -------------------------
    def _call_azure_openai(self, messages: list, temperature: float = 0.2, max_tokens: int = 2048) -> str:
        try:
            completion = client_azure.chat.completions.create(
                model=AZURE_OPENAI_DEPLOYMENT,
                messages=messages,
                temperature=temperature,
                max_tokens=max_tokens,
            )
            return completion.choices[0].message.content
        except Exception as e:
            logger.error(f"Azure OpenAI API error: {e}")
            return json.dumps({"error": str(e)})

    # -------------------- MCP TOOL CALLS -------------------------
    async def list_tools(self) -> dict:
        try:
            if not self.session:
                await self.connect()
            tools_list = await self.session.list_tools()
            tools_dict = {tool.name: {"description": tool.description, "inputSchema": tool.inputSchema} for tool in tools_list.tools}
            return {"tools": tools_dict}
        except Exception as e:
            logger.error(f"Error listing tools: {e}")
            return {"error": str(e)}

    async def invoke_tool(self, tool_name: str, args: dict) -> dict:
        try:
            if not self.session:
                await self.connect()
            logger.info(f"Calling tool: {tool_name} with args: {args}")
            result = await self.session.call_tool(tool_name, args)

            if result.content:
                content_items = []
                for item in result.content:
                    if hasattr(item, 'text'):
                        try:
                            content_items.append(json.loads(item.text))
                        except json.JSONDecodeError:
                            content_items.append(item.text)
                if len(content_items) == 1:
                    return content_items[0]
                return {"results": content_items}

            return {"error": "No content in response"}
        except Exception as e:
            logger.error(f"Error invoking tool {tool_name}: {e}")
            return {"error": str(e)}

    # -------------------- LLM PLANNING & SUMMARIZATION -------------------------
    def plan_tools(self, user_query: str) -> dict:
        """
        Ask the LLM to produce a valid JSON plan for which MCP tools to call.
        Cleans out Markdown-style fences (```json ... ```), which some models add.`````
        """
        messages = [
            {"role": "system", "content": SYSTEM_PROMPT_PLAN},
            {"role": "user", "content": user_query},
        ]

        content = self._call_azure_openai(messages, temperature=0.1)
        if not content:
            logger.warning("‚ö†Ô∏è LLM returned empty response during plan generation.")
            return {"plan": []}

        
        cleaned = content.strip()
        if cleaned.startswith("```"):
            
            cleaned = cleaned.strip("`")
            if cleaned.lower().startswith("json"):
                cleaned = cleaned[4:].strip()
            
            cleaned = cleaned.replace("```", "").strip()

        
        if cleaned != content:
            logger.debug(f"üîç Cleaned LLM plan output:\n{cleaned}")

       
        try:
            plan = json.loads(cleaned)
            if isinstance(plan, dict) and "plan" in plan:
                return plan
            else:
                logger.warning("‚ö†Ô∏è LLM output did not contain 'plan' key.")
                return {"plan": []}
        except json.JSONDecodeError:
            logger.warning(f"‚ùå Could not parse LLM plan output after cleaning:\n{cleaned}")
            return {"plan": []}


    def summarize_results(self, user_query: str, plan: list, results: list) -> dict:
        messages = [
            {"role": "system", "content": SYSTEM_PROMPT_SUMMARIZE},
            {"role": "user", "content": f"Question:\n{user_query}"},
            {"role": "assistant", "content": f"Plan:\n{json.dumps(plan, indent=2)}"},
            {"role": "assistant", "content": f"Results:\n{json.dumps(results, indent=2)}"},
        ]
        summary = self._call_azure_openai(messages, temperature=0.3)
        return {"summary": summary}

   
    async def run_query(self, user_query: str) -> dict:
        """
        Full flow:
        1. LLM plans which tools to call (including possible MongoDB query).
        2. Execute tools sequentially via MCP.
        3. Summarize results using LLM.
        """
        try:
            logger.info(f"User query: {user_query}")
            plan_data = self.plan_tools(user_query)
            plan = plan_data.get("plan", [])
            if not plan:
                return {"error": "LLM did not produce a valid tool plan."}

            results = []
            for step in plan:
                tool = step.get("tool")
                args = step.get("arguments", {})

                # Clean up bad args
                args = {k: v for k, v in args.items() if v and str(v).strip().lower() != "unknown"}

                # Safety for MongoDB query
                if tool == "raw_mongodb_query":
                    query_json = args.get("query_json", "")
                    if not query_json:
                        results.append({"raw_mongodb_query": {"error": "Empty query_json"}})
                        continue
                    # Enforce safe default limit
                    args["limit"] = int(args.get("limit", 50))
                    logger.info(f"Executing raw MongoDB query: {query_json}")

                resp = await self.invoke_tool(tool, args)
                results.append({tool: resp})

            summary = self.summarize_results(user_query, plan, results)
            return {"plan": plan, "results": results, "summary": summary}
        except Exception as e:
            logger.error(f"Error in run_query: {e}")
            return {"error": str(e)}
  ###################################################################
  (venv1) PS C:\Users\Deeksha.x.Srivastava\OneDrive - InterGlobe Aviation Limited\Desktop\ag_chatbot\backend> python ag_ui_server.py
üöÄ Starting FlightOps AG-UI Server...
INFO:     Started server process [15520]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8001 (Press CTRL+C to quit)
INFO:     127.0.0.1:57252 - "OPTIONS /agent HTTP/1.1" 200 OK
üì• Processing query: give me base station of flight 6E 215
INFO:     127.0.0.1:57252 - "POST /agent HTTP/1.1" 200 OK
INFO:FlightOps.MCPClient:Connecting to MCP server at http://127.0.0.1:8000/mcp
INFO:httpx:HTTP Request: POST http://127.0.0.1:8000/mcp "HTTP/1.1 200 OK"
INFO:mcp.client.streamable_http:Received session ID: 7d84c9b12be5486bb0b15c773b81c94b
INFO:mcp.client.streamable_http:Negotiated protocol version: 2025-06-18
INFO:FlightOps.MCPClient:‚úÖ Connected to MCP server successfully
INFO:FlightOps.MCPClient:User query: give me base station of flight 6E 215
INFO:httpx:HTTP Request: POST https://6e-openai-sandbox-aops.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
WARNING:FlightOps.MCPClient:‚ùå Could not parse LLM plan output after cleaning:
To determine the base station of flight 6E 215, I will retrieve its basic flight information.

```json
{
  "plan": [
    {
      "tool": "get_flight_basic_info",
      "arguments": {
        "carrier": "6E",
        "flight_number": "215",
        "date_of_origin": null
      }
    }
  ]
}
```
INFO:httpx:HTTP Request: POST http://127.0.0.1:8000/mcp "HTTP/1.1 202 Accepted"
INFO:httpx:HTTP Request: GET http://127.0.0.1:8000/mcp "HTTP/1.1 200 OK"
üì• Processing query: give me base station of flight 6E 215
INFO:     127.0.0.1:51034 - "POST /agent HTTP/1.1" 200 OK
INFO:FlightOps.MCPClient:User query: give me base station of flight 6E 215
INFO:httpx:HTTP Request: POST https://6e-openai-sandbox-aops.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
WARNING:FlightOps.MCPClient:‚ùå Could not parse LLM plan output after cleaning:
To determine the base station of flight 6E 215, I will retrieve the basic flight information.

```json
{
  "plan": [
    {
      "tool": "get_flight_basic_info",
      "arguments": {
        "carrier": "6E",
        "flight_number": "215",
        "date_of_origin": null
      }
    }
  ]
}
```
üì• Processing query: give me base station of flight 6E 215
INFO:     127.0.0.1:60799 - "POST /agent HTTP/1.1" 200 OK
INFO:FlightOps.MCPClient:User query: give me base station of flight 6E 215
INFO:httpx:HTTP Request: POST https://6e-openai-sandbox-aops.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
WARNING:FlightOps.MCPClient:‚ùå Could not parse LLM plan output after cleaning:
To provide the base station of flight 6E 215, I will retrieve the basic flight information.

```json
{
  "plan": [
    {
      "tool": "get_flight_basic_info",
      "arguments": {
        "carrier": "6E",
        "flight_number": "215",
        "date_of_origin": null
      }
    }
  ]
}
```
INFO:     127.0.0.1:59411 - "OPTIONS /agent HTTP/1.1" 200 OK
üì• Processing query: give details of flight 6E 215
INFO:     127.0.0.1:59411 - "POST /agent HTTP/1.1" 200 OK
INFO:FlightOps.MCPClient:User query: give details of flight 6E 215
INFO:httpx:HTTP Request: POST https://6e-openai-sandbox-aops.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
WARNING:FlightOps.MCPClient:‚ùå Could not parse LLM plan output after cleaning:
To provide details about flight 6E 215, I will use the `get_flight_basic_info` tool. Since you haven't provided a specific date, I will need the date of origin for this flight to proceed. Could you please provide the date of origin?
üì• Processing query: give details of flight 6E 215
INFO:     127.0.0.1:49215 - "POST /agent HTTP/1.1" 200 OK
INFO:FlightOps.MCPClient:User query: give details of flight 6E 215
INFO:httpx:HTTP Request: POST https://6e-openai-sandbox-aops.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
WARNING:FlightOps.MCPClient:‚ùå Could not parse LLM plan output after cleaning:
To provide details about flight 6E 215, I will use the `get_flight_basic_info` tool. Since you haven't provided a specific date, I will need the date of origin for this flight. Could you please provide the date of origin?
###################################################################
import os
import uuid
import json
import asyncio
from typing import AsyncGenerator
from fastapi import FastAPI, Request, HTTPException
from fastapi.responses import StreamingResponse
from fastapi.middleware.cors import CORSMiddleware
from dotenv import load_dotenv

load_dotenv()

app = FastAPI(title="FlightOps AG-UI Server")

# Add CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Restrict in production
    allow_methods=["*"],
    allow_headers=["*"],
)

# Import AG-UI components
try:
    from ag_ui.core import (
        RunAgentInput,
        EventType,
        RunStartedEvent,
        RunFinishedEvent,
        RunErrorEvent,
        TextMessageStartEvent,
        TextMessageContentEvent,
        TextMessageEndEvent,
    )
    from ag_ui.encoder import EventEncoder
    AGUI_AVAILABLE = True
except ImportError:
    AGUI_AVAILABLE = False
    print("‚ö†Ô∏è AG-UI not installed, using fallback")

from client import FlightOpsMCPClient

class FlightOpsAgent:
    def __init__(self):
        self.mcp_client = FlightOpsMCPClient()
        self.connected = False

    async def ensure_connected(self):
        """Ensure MCP client is connected"""
        if not self.connected:
            await self.mcp_client.connect()
            self.connected = True

    async def process_query(self, user_message: str):
        """Process user query and return results"""
        await self.ensure_connected()
        return await self.mcp_client.run_query(user_message)

# Global agent instance
agent = FlightOpsAgent()

@app.post("/agent")
async def agent_endpoint(request: Request):
    """Main AG-UI agent endpoint"""
    if not AGUI_AVAILABLE:
        raise HTTPException(status_code=500, detail="AG-UI not available")

    try:
        # Parse request
        body = await request.json()
        
        # Extract user message
        messages = body.get("messages", [])
        user_message = None
        
        for msg in messages:
            if msg.get("role") == "user":
                user_message = msg.get("content", "")
                break
        
        if not user_message:
            raise HTTPException(status_code=400, detail="No user message found")

        print(f"üì• Processing query: {user_message}")

        # Get accept header for encoder
        accept_header = request.headers.get("accept", "text/event-stream")
        encoder = EventEncoder(accept=accept_header)

        async def generate_events():
            """Generate AG-UI events"""
            try:
                # Emit run started
                yield encoder.encode(RunStartedEvent(
                    type=EventType.RUN_STARTED,
                    thread_id=body.get("thread_id", "default"),
                    run_id=body.get("run_id", f"run-{uuid.uuid4().hex[:8]}")
                ))

                # Process the query
                result = await agent.process_query(user_message)
                
                # Extract response text
                if isinstance(result, dict):
                    if "summary" in result and isinstance(result["summary"], dict):
                        response_text = result["summary"].get("summary", "No summary available")
                    elif "summary" in result:
                        response_text = result["summary"]
                    elif "error" in result:
                        response_text = f"Error: {result['error']}"
                    else:
                        response_text = json.dumps(result, indent=2)
                else:
                    response_text = str(result)

                # Ensure response_text is a string
                if not isinstance(response_text, str):
                    response_text = str(response_text)

                # Emit text message start
                message_id = f"msg-{uuid.uuid4().hex[:8]}"
                yield encoder.encode(TextMessageStartEvent(
                    type=EventType.TEXT_MESSAGE_START,
                    message_id=message_id,
                    role="assistant"
                ))

                # Stream response word by word
                if response_text:
                    words = response_text.split()
                    for word in words:
                        yield encoder.encode(TextMessageContentEvent(
                            type=EventType.TEXT_MESSAGE_CONTENT,
                            message_id=message_id,
                            delta=word + " "
                        ))
                        await asyncio.sleep(0.05)  # Simulate streaming

                # Emit text message end
                yield encoder.encode(TextMessageEndEvent(
                    type=EventType.TEXT_MESSAGE_END,
                    message_id=message_id
                ))

                # Emit run finished
                yield encoder.encode(RunFinishedEvent(
                    type=EventType.RUN_FINISHED,
                    thread_id=body.get("thread_id", "default"),
                    run_id=body.get("run_id", f"run-{uuid.uuid4().hex[:8]}")
                ))

            except Exception as error:
                print(f"‚ùå Error in event generation: {error}")
                yield encoder.encode(RunErrorEvent(
                    type=EventType.RUN_ERROR,
                    message=str(error)
                ))

        return StreamingResponse(
            generate_events(),
            media_type="text/event-stream",
            headers={
                "Cache-Control": "no-cache",
                "Connection": "keep-alive",
                "Access-Control-Allow-Origin": "*",
            }
        )

    except Exception as e:
        print(f"‚ùå Server error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/")
async def root():
    return {"status": "healthy", "service": "FlightOps AG-UI Server"}

@app.get("/health")
async def health_check():
    """Health check endpoint"""
    try:
        await agent.ensure_connected()
        tools = await agent.mcp_client.list_tools()
        return {
            "status": "healthy",
            "mcp_connected": True,
            "tools_available": len(tools.get("tools", {})),
            "ag_ui_available": AGUI_AVAILABLE
        }
    except Exception as e:
        return {
            "status": "unhealthy",
            "mcp_connected": False,
            "error": str(e),
            "ag_ui_available": AGUI_AVAILABLE
        }

@app.get("/tools")
async def list_tools():
    """List available MCP tools"""
    try:
        await agent.ensure_connected()
        return await agent.mcp_client.list_tools()
    except Exception as e:
        return {"error": str(e)}

@app.post("/query")
async def direct_query(request: Request):
    """Direct query endpoint for testing"""
    body = await request.json()
    user_query = body.get("query", "")
    
    try:
        result = await agent.process_query(user_query)
        return result
    except Exception as e:
        return {"error": str(e)}

if __name__ == "__main__":
    import uvicorn
    print("üöÄ Starting FlightOps AG-UI Server...")
    uvicorn.run(app, host="0.0.0.0", port=8001, log_level="info")
